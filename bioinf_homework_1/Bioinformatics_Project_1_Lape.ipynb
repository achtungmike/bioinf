{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bowtie Prep\n",
    "Bowtie(1.2.2) was downloaded.\n",
    "Built indexes using a lower offrate value which will increase the size of index on disk and in memory but should help with the alignment when using the -a command.\n",
    "    python c:/bowtie/bowtie-build --offrate 3 ..\\data\\ames\\ames.fasta  ..\\data\\ames\\ames    \n",
    "    python c:/bowtie/bowtie-build --offrate 3 ..\\data\\sterne\\sterne.fasta  ..\\data\\sterne\\sterne \n",
    "    \n",
    "    \n",
    "# Generate tandem repeat library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T23:37:59.069733Z",
     "start_time": "2018-02-04T23:37:53.663228Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "\n",
    "# Define our library of chars and build our tandem repeats strings\n",
    "lib = ('A', 'T', 'C','G')\n",
    "\n",
    "\n",
    "# Repeat Length (n)  ==> Number of possible tandem repeats (len(lib)^n = 4^n)\n",
    "# 6  ==>        4,096\n",
    "# 7  ==>       16,384\n",
    "# 8  ==>       65,536\n",
    "# 9  ==>      262,144\n",
    "# 10 ==>    1,048,576\n",
    "\n",
    "# This could be shrunk into 1 big for loop to output 1 list of all lenghts\n",
    "# since bowtie outputs the matched query, you could collapse all the outputs into a map\n",
    "# match1 -> index1, index2, index3\n",
    "# match2 -> index4, index5\n",
    "# and then you just need to take the len(match1) to determine the jump distance to determine if \n",
    "# index1 and 2 are close enough to be considered tandem repeats\n",
    "\n",
    "# generate tandem repeat library\n",
    "six = []\n",
    "for i in it.product(lib, repeat=6):\n",
    "    six.append(''.join(map(str, i)))\n",
    "\n",
    "sev = []\n",
    "for i in it.product(lib, repeat=7):\n",
    "    sev.append(''.join(map(str, i)))\n",
    "\n",
    "eight = []\n",
    "for i in it.product(lib, repeat=8):\n",
    "    eight.append(''.join(map(str, i)))\n",
    "\n",
    "nine = []\n",
    "for i in it.product(lib, repeat=9):\n",
    "    nine.append(''.join(map(str, i)))\n",
    "    \n",
    "ten = []\n",
    "for i in it.product(lib, repeat=10):\n",
    "    ten.append(''.join(map(str, i)))\n",
    "\n",
    "\n",
    "# Function to output results to individual files\n",
    "def out(filename, dat):\n",
    "    f = open(filename, \"w\")\n",
    "    for i in dat:\n",
    "        f.write(\"\\'\"+i+\"\\'\\n\")\n",
    "    f.close()\n",
    "\n",
    "out(\"data/lib/six\", six)\n",
    "out(\"data/lib/sev\", sev)\n",
    "out(\"data/lib/eight\", eight)\n",
    "out(\"data/lib/nine\", nine)\n",
    "out(\"data/lib/ten\", ten)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for tandem repeats\n",
    "We have our tandem repeat library and our bowtie indices of interest.\n",
    "We are only interested in tandem repeats of length 3+ (that is 3 or more repeats of the same library entry)\n",
    "\n",
    "bowtie options:\n",
    "--suppress 1,2,3,6,7,8 [Leave only the columns we are intrested in, query and loc]\n",
    "-t [time to process]\n",
    "-p 4 [use 4 threads]\n",
    "-a   [find all matches]\n",
    "-v 0 [no mismatches allowed]\n",
    "-r input file [our file that contains the queries]\n",
    "\n",
    "#### Ames\n",
    "python c:\\bowtie\\bowtie ames/ames -r lib/six -a -v 0 -t -p 4 --suppress 1,2,3,6,7,8 > ames/out/six.out 2> ames/out/six.err  \n",
    "Time loading forward index: 00:00:00\n",
    "    Time for 0-mismatch search: 00:00:13\n",
    "    #reads processed: 4096\n",
    "    #reads with at least one reported alignment: 4096 (100.00%)\n",
    "    #reads that failed to align: 0 (0.00%)\n",
    "    Reported 14139938 alignments\n",
    "    Time searching: 00:00:13\n",
    "    Overall time: 00:00:13\n",
    "\n",
    "python c:\\bowtie\\bowtie ames/ames -r lib/sev -a -v 0 -t -p 4 --suppress 1,2,3,6,7,8 > ames/out/sev.out 2> ames/out/sev.err  \n",
    "    Time loading forward index: 00:00:00\n",
    "    Time for 0-mismatch search: 00:00:13\n",
    "    #reads processed: 16384\n",
    "    #reads with at least one reported alignment: 16384 (100.00%)\n",
    "    #reads that failed to align: 0 (0.00%)\n",
    "    Reported 14167641 alignments\n",
    "    Time searching: 00:00:13\n",
    "    Overall time: 00:00:13\n",
    "\n",
    "python c:\\bowtie\\bowtie ames/ames -r lib/eight -a -v 0 -t -p 4 --suppress 1,2,3,6,7,8 > ames/out/eight.out 2> ames/out/eight.err  \n",
    "    Time loading forward index: 00:00:00\n",
    "    Time for 0-mismatch search: 00:00:13\n",
    "    #reads processed: 65536\n",
    "    #reads with at least one reported alignment: 65530 (99.99%)\n",
    "    #reads that failed to align: 6 (0.01%)\n",
    "    Reported 14177830 alignments\n",
    "    Time searching: 00:00:13\n",
    "    Overall time: 00:00:13\n",
    "\n",
    "python c:\\bowtie\\bowtie ames/ames -r lib/nine -a -v 0 -t -p 4 --suppress 1,2,3,6,7,8 > ames/out/nine.out 2> ames/out/nine.err  \n",
    "    Time loading forward index: 00:00:00\n",
    "    Time for 0-mismatch search: 00:00:15\n",
    "    #reads processed: 262144\n",
    "    #reads with at least one reported alignment: 260224 (99.27%)\n",
    "    #reads that failed to align: 1920 (0.73%)\n",
    "    Reported 14181366 alignments\n",
    "    Time searching: 00:00:15\n",
    "    Overall time: 00:00:15\n",
    "\n",
    "python c:\\bowtie\\bowtie ames/ames -r lib/ten -a -v 0 -t -p 4 --suppress 1,2,3,6,7,8 > ames/out/ten.out 2> ames/out/ten.err  \n",
    "    Time loading forward index: 00:00:00\n",
    "    Time for 0-mismatch search: 00:00:18\n",
    "    #reads processed: 1048576\n",
    "    #reads with at least one reported alignment: 950147 (90.61%)\n",
    "    #reads that failed to align: 98429 (9.39%)\n",
    "    Reported 14181700 alignments\n",
    "    Time searching: 00:00:18\n",
    "    Overall time: 00:00:18\n",
    "\n",
    "\n",
    "#### Sterne\n",
    "python c:\\bowtie\\bowtie sterne/sterne -r lib/six -a -v 0 -t -p 4 --suppress 1,2,3,6,7,8 > sterne/out/six.out 2> sterne/out/six.err  \n",
    "    Time loading forward index: 00:00:00\n",
    "    Time for 0-mismatch search: 00:00:13\n",
    "    #reads processed: 4096\n",
    "    #reads with at least one reported alignment: 4096 (100.00%)\n",
    "    #reads that failed to align: 0 (0.00%)\n",
    "    Reported 14143170 alignments\n",
    "    Time searching: 00:00:13\n",
    "    Overall time: 00:00:13\n",
    "\n",
    "python c:\\bowtie\\bowtie sterne/sterne -r lib/sev -a -v 0 -t -p 4 --suppress 1,2,3,6,7,8 > sterne/out/sev.out 2> sterne/out/sev.err  \n",
    "    Time loading forward index: 00:00:00\n",
    "    Time for 0-mismatch search: 00:00:13\n",
    "    #reads processed: 16384\n",
    "    #reads with at least one reported alignment: 16384 (100.00%)\n",
    "    #reads that failed to align: 0 (0.00%)\n",
    "    Reported 14170873 alignments\n",
    "    Time searching: 00:00:13\n",
    "    Overall time: 00:00:13\n",
    "\n",
    "\n",
    "python c:\\bowtie\\bowtie sterne/sterne -r lib/eight -a -v 0 -t -p 4 --suppress 1,2,3,6,7,8 > sterne/out/eight.out 2> sterne/out/eight.err  \n",
    "    Time loading forward index: 00:00:00\n",
    "    Time for 0-mismatch search: 00:00:13\n",
    "    #reads processed: 65536\n",
    "    #reads with at least one reported alignment: 65530 (99.99%)\n",
    "    #reads that failed to align: 6 (0.01%)\n",
    "    Reported 14181071 alignments\n",
    "    Time searching: 00:00:13\n",
    "    Overall time: 00:00:13\n",
    "\n",
    "python c:\\bowtie\\bowtie sterne/sterne -r lib/nine -a -v 0 -t -p 4 --suppress 1,2,3,6,7,8 > sterne/out/nine.out 2> sterne/out/nine.err  \n",
    "    Time loading forward index: 00:00:00\n",
    "    Time for 0-mismatch search: 00:00:14\n",
    "    #reads processed: 262144\n",
    "    #reads with at least one reported alignment: 260230 (99.27%)\n",
    "    #reads that failed to align: 1914 (0.73%)\n",
    "    Reported 14184603 alignments\n",
    "    Time searching: 00:00:14\n",
    "    Overall time: 00:00:14\n",
    "\n",
    "\n",
    "python c:\\bowtie\\bowtie sterne/sterne -r lib/ten -a -v 0 -t -p 4 --suppress 1,2,3,6,7,8 > sterne/out/ten.out 2> sterne/out/ten.err  \n",
    "    Time loading forward index: 00:00:00\n",
    "    Time for 0-mismatch search: 00:00:14\n",
    "    #reads processed: 1048576\n",
    "    #reads with at least one reported alignment: 950217 (90.62%)\n",
    "    #reads that failed to align: 98359 (9.38%)\n",
    "    Reported 14184944 alignments\n",
    "    Time searching: 00:00:14\n",
    "    Overall time: 00:00:14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output\n",
    "1st column is index of where the match starts.\n",
    "2nd column is the matching query sequence.\n",
    "\n",
    "### Example:\n",
    "280045\tAACAA\n",
    "290018\tAACAA\n",
    "9256\tAACAA\n",
    "741380\tAACAA\n",
    "145436\tAACAA\n",
    "29050\tAACAA\n",
    "532426\tAACAA\n",
    "82371\tAACAA\n",
    "266746\tAACAA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T23:37:59.170502Z",
     "start_time": "2018-02-04T23:37:59.072742Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# This function takes a file path (please have r appended to the front for paths on windows)\n",
    "# and generates a repeat dictionary.  This repeat dictionary has sequences as the key\n",
    "# and an ordered list with no dupes as the value.  This ordered list contains each location\n",
    "# in the genome that this sequence was found in asc order.\n",
    "\n",
    "def create_rep_dict(filepath):\n",
    "    file = filepath\n",
    "    # dictionary that will use repeat sequence as key, and keep location values\n",
    "    tan_dict = dict()\n",
    "\n",
    "    with open(file, \"r\") as input:\n",
    "        line = input.read().splitlines()\n",
    "        # Loop through each line in file and deal with it\n",
    "        for i in line:\n",
    "            val = i.split()\n",
    "            seq = val[1]\n",
    "            loc = int(val[0])\n",
    "            if seq in tan_dict:\n",
    "               # append the new loc to the existing array for this seq.\n",
    "                tan_dict[seq].append(loc)\n",
    "            else:\n",
    "               # create a new array for this seq\n",
    "                tan_dict[seq] = [loc]\n",
    "\n",
    "        # Ugly probably slow hack, removes all seqs with less than 3 locs since they couldn't be a tandem repeat\n",
    "        # also sorts and uniques the list of locs for seqs\n",
    "        for k in list(tan_dict.keys()):\n",
    "            if(len(tan_dict[k]) > 2):\n",
    "                tan_dict[k] = list(sorted(set(tan_dict[k])))\n",
    "            else:\n",
    "                del tan_dict[k]\n",
    "\n",
    "    return tan_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T23:37:59.251216Z",
     "start_time": "2018-02-04T23:37:59.174013Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# This function takes the a prepared tandem repeat dictionary.\n",
    "# This dictionary needs to have the key set as a sequence, with the \n",
    "# value for each key being an ordered list with no dupes of the locations\n",
    "# within the genome the seq was found.\n",
    "\n",
    "# It determines the number max tandem repeat seen in the genome for\n",
    "# a particular sequence, and returns a dict with the seq as they key\n",
    "# and the number of repeats as the value.\n",
    "\n",
    "# Note that this function only returns the max number of repeats so if your\n",
    "# seq has to separate tandem repeats, 1 of 3 repeats and another of 7, it will \n",
    "# only return a value of 7.\n",
    "\n",
    "def finds_reps(tan_rep_dict):\n",
    "    REPEAT_LEN = len(list(tan_rep_dict.keys())[-1])\n",
    "\n",
    "    tan_dict = tan_rep_dict\n",
    "\n",
    "    # Loop through all sequences\n",
    "    for k in list(tan_dict.keys()):\n",
    "        # assign the list of locs for this seq to locs\n",
    "        locs = tan_dict[k]\n",
    "        rep_len = [0]\n",
    "        count = 1\n",
    "        max_count = 1\n",
    "        prev_loc = locs[0]\n",
    "\n",
    "        for loc in locs:\n",
    "            dist = loc - prev_loc\n",
    "\n",
    "            # Too short to be a repeat\n",
    "            if dist < REPEAT_LEN:\n",
    "                continue\n",
    "            # We have a repeat\n",
    "            if dist == REPEAT_LEN:\n",
    "                count += 1\n",
    "\n",
    "            if dist > REPEAT_LEN:\n",
    "                # Store this count if its greater than our longest count seen so far and reset\n",
    "                max_count = max(max_count, count)\n",
    "                count = 1\n",
    "\n",
    "            prev_loc = loc\n",
    "\n",
    "\n",
    "        # no tandem repeats for this sequence so drop it from the dict\n",
    "        # otherwise if there is replace the locs with the max number of repeats seen.\n",
    "        if max_count < 3:\n",
    "            del tan_dict[k]\n",
    "        else:\n",
    "            tan_dict[k] = max_count\n",
    "\n",
    "    return tan_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T23:41:19.290014Z",
     "start_time": "2018-02-04T23:37:59.259238Z"
    },
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Handling output.  Output files need to be read in for processing.\n",
    "\n",
    "# dict to hold our identified ames tandem repeats\n",
    "ames_reps = dict()\n",
    "\n",
    "# go through each file 6-10 adding tandem repeats to ames_reps dict\n",
    "# 6\n",
    "reps_dict = create_rep_dict(r'C:\\Users\\Mike\\Desktop\\Mike\\UC\\Spring_2018\\BMIN7099_Bioinformatics\\hw\\homework_1\\data\\ames\\out\\six.out')\n",
    "ames_reps.update(finds_reps(reps_dict))\n",
    "\n",
    "# 7\n",
    "reps_dict = create_rep_dict(r'C:\\Users\\Mike\\Desktop\\Mike\\UC\\Spring_2018\\BMIN7099_Bioinformatics\\hw\\homework_1\\data\\ames\\out\\sev.out')\n",
    "ames_reps.update(finds_reps(reps_dict))\n",
    "\n",
    "# 8\n",
    "reps_dict = create_rep_dict(r'C:\\Users\\Mike\\Desktop\\Mike\\UC\\Spring_2018\\BMIN7099_Bioinformatics\\hw\\homework_1\\data\\ames\\out\\eight.out')\n",
    "ames_reps.update(finds_reps(reps_dict))\n",
    "\n",
    "# 9\n",
    "reps_dict = create_rep_dict(r'C:\\Users\\Mike\\Desktop\\Mike\\UC\\Spring_2018\\BMIN7099_Bioinformatics\\hw\\homework_1\\data\\ames\\out\\nine.out')\n",
    "ames_reps.update(finds_reps(reps_dict))\n",
    "\n",
    "# 10\n",
    "reps_dict = create_rep_dict(r'C:\\Users\\Mike\\Desktop\\Mike\\UC\\Spring_2018\\BMIN7099_Bioinformatics\\hw\\homework_1\\data\\ames\\out\\ten.out')\n",
    "ames_reps.update(finds_reps(reps_dict))\n",
    "\n",
    "\n",
    "\n",
    "# dict to hold our identified sterne tandem repeats\n",
    "sterne_reps = dict()\n",
    "\n",
    "# go through each file 6-10 adding tandem repeats to sterne_reps dict\n",
    "# 6\n",
    "reps_dict = create_rep_dict(r'C:\\Users\\Mike\\Desktop\\Mike\\UC\\Spring_2018\\BMIN7099_Bioinformatics\\hw\\homework_1\\data\\sterne\\out\\six.out')\n",
    "sterne_reps.update(finds_reps(reps_dict))\n",
    "\n",
    "# 7\n",
    "reps_dict = create_rep_dict(r'C:\\Users\\Mike\\Desktop\\Mike\\UC\\Spring_2018\\BMIN7099_Bioinformatics\\hw\\homework_1\\data\\sterne\\out\\sev.out')\n",
    "sterne_reps.update(finds_reps(reps_dict))\n",
    "\n",
    "# 8\n",
    "reps_dict = create_rep_dict(r'C:\\Users\\Mike\\Desktop\\Mike\\UC\\Spring_2018\\BMIN7099_Bioinformatics\\hw\\homework_1\\data\\sterne\\out\\eight.out')\n",
    "sterne_reps.update(finds_reps(reps_dict))\n",
    "\n",
    "# 9\n",
    "reps_dict = create_rep_dict(r'C:\\Users\\Mike\\Desktop\\Mike\\UC\\Spring_2018\\BMIN7099_Bioinformatics\\hw\\homework_1\\data\\sterne\\out\\nine.out')\n",
    "sterne_reps.update(finds_reps(reps_dict))\n",
    "\n",
    "# 10\n",
    "reps_dict = create_rep_dict(r'C:\\Users\\Mike\\Desktop\\Mike\\UC\\Spring_2018\\BMIN7099_Bioinformatics\\hw\\homework_1\\data\\sterne\\out\\ten.out')\n",
    "sterne_reps.update(finds_reps(reps_dict))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T23:44:03.138014Z",
     "start_time": "2018-02-04T23:44:03.122471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tandem repeats in Ames:  60\n",
      "Number of tandem repeats in Sterne:  85\n",
      "Number of tandem repeats in existing in both:  54\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tabulate as tab\n",
    "\n",
    "ames_set = set(ames_reps.keys())\n",
    "sterne_set = set(sterne_reps.keys())\n",
    "\n",
    "inter = ames_set & sterne_set\n",
    "print(\"Number of tandem repeats in Ames: \", len(ames_set))\n",
    "print(\"Number of tandem repeats in Sterne: \", len(sterne_set))\n",
    "print(\"Number of tandem repeats in existing in both: \", len(inter))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T23:37:48.169185Z",
     "start_time": "2018-02-04T23:37:48.144Z"
    }
   },
   "outputs": [],
   "source": [
    "inter_reps = dict()\n",
    "\n",
    "for i in inter:\n",
    "    # Loop through and save any where the number seen in ames and stern differ\n",
    "    if ames_reps[i] != sterne_reps[i]:\n",
    "        inter_reps[i] = (ames_reps[i], sterne_reps[i])\n",
    "        print(len(i))\n",
    "\n",
    "print(\"Number of tandem repeats seen at different lengths: \", len(inter_reps))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T23:51:40.689524Z",
     "start_time": "2018-02-04T23:51:40.653927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GTGTTT': 3, 'ATTTTT': 3, 'AAAAAC': 3, 'TATTTT': 3, 'AAAACA': 3, 'ATTATT': 3, 'AATCAC': 3, 'AACAAA': 3, 'AACAAG': 4, 'TGTGTT': 3, 'AAGAAC': 3, 'TATTAT': 3, 'GTATAT': 3, 'CTGAAT': 3, 'CACAAT': 4, 'ATCACA': 4, 'ATCTGA': 3, 'ATGAAA': 3, 'ACAAAA': 3, 'ACAATC': 4, 'ACAAGA': 4, 'AGAACA': 3, 'AGAAGA': 3, 'AGGTGA': 3, 'TTATTA': 3, 'TGTATA': 3, 'CAAAAA': 3, 'GAAGAA': 3, 'CAAGAA': 4, 'GGTGAA': 3, 'TCTGAA': 3, 'GAACAA': 3, 'TCACAA': 4, 'CAATCA': 4, 'TGAAGG': 3, 'GTTACA': 3, 'GTGAAG': 3, 'AATATCC': 5, 'ATATCCA': 5, 'CCAATAT': 4, 'ATCCAAT': 5, 'ACACCAG': 3, 'ACCAGAC': 3, 'AGACACC': 3, 'TCCAATA': 4, 'TATCCAA': 5, 'CACCAGA': 3, 'CCAGACA': 3, 'CAATATC': 5, 'CAGACAC': 3, 'GTAGCGAT': 3, 'ATGTAGCG': 3, 'AGCGATGT': 3, 'GCGATGTA': 3, 'TAGCGATG': 3, 'TGTAGCGA': 3, 'GATGTAGC': 3, 'ACCTACTGG': 3, 'GGACCTACT': 3, 'GACCTACTG': 3}\n",
      "{'GTGTTT': 3, 'AAAAAA': 3, 'ATTTTT': 3, 'AAAAAC': 3, 'TATTTT': 3, 'AAAACA': 3, 'ATTATT': 5, 'AATCAC': 3, 'AACAAA': 3, 'AACAAG': 4, 'TGTGTT': 3, 'AAGAAC': 3, 'TATTAT': 5, 'GTATAT': 3, 'CTGAAT': 3, 'CACAAT': 4, 'ATCACA': 4, 'ATCTGA': 3, 'ATGAAA': 3, 'ACAAAA': 3, 'ACAATC': 4, 'ACAAGA': 4, 'AGAACA': 3, 'AGAAGA': 3, 'AGGTGA': 3, 'TTATTA': 4, 'TGTATA': 3, 'CAAAAA': 3, 'GGTGAA': 3, 'TCTGAA': 3, 'GAAGAA': 3, 'CAAGAA': 4, 'GAACAA': 3, 'TCACAA': 4, 'CAATCA': 4, 'TGAAGG': 3, 'GTTACA': 3, 'GTGAAG': 3, 'AATATCC': 5, 'ATATCCA': 5, 'CCAATAT': 4, 'ATCCAAT': 5, 'TCCAATA': 4, 'TATCCAA': 5, 'CAATATC': 5, 'GTAGCGAT': 3, 'ATGTAGCG': 3, 'AGCGATGT': 3, 'GCGATGTA': 3, 'TAGCGATG': 3, 'TGTAGCGA': 3, 'GATGTAGC': 3, 'CTCCCGTTT': 3, 'ATTATTATT': 3, 'GTTGATATT': 3, 'GATATTGTT': 3, 'GCTCCTGTT': 3, 'TATTATTAT': 3, 'ATATTGTTG': 3, 'TGTTGATAT': 3, 'TGATATTGT': 3, 'TGCTCCTGT': 3, 'ACTGGACCT': 3, 'ACCTACTGG': 4, 'CCCGTTTCT': 3, 'GGACCTACT': 4, 'CCTGTTGCT': 3, 'GTTGCTCCT': 3, 'TTATTATTA': 3, 'TTGTTGATA': 3, 'TACTGGACC': 3, 'CTGGACCTA': 3, 'TTGATATTG': 3, 'TTGCTCCTG': 3, 'CCTACTGGA': 3, 'TCCTGTTGC': 3, 'TCCCGTTTC': 3, 'TGTTGCTCC': 3, 'TGGACCTAC': 3, 'CTCCTGTTG': 3, 'GACCTACTG': 4, 'CTACTGGAC': 3, 'CTGTTGCTC': 3, 'CCGTTTCTC': 3, 'CGTTTCTCC': 3}\n",
      "Tandem Repeat      Ames Len    Sterne Len    Difference\n",
      "---------------  ----------  ------------  ------------\n",
      "ACCTACTGG                 3             4            -1\n",
      "ATTATT                    3             5            -2\n",
      "GACCTACTG                 3             4            -1\n",
      "GGACCTACT                 3             4            -1\n",
      "TATTAT                    3             5            -2\n",
      "TTATTA                    3             4            -1\n",
      "Total (+ means ames is longer, - means Sterne is longer) -8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tabulate as tab\n",
    "# Generate sets of the keys so we can intersect\n",
    "\n",
    "ames_set = set(ames_reps.keys())\n",
    "sterne_set = set(sterne_reps.keys())\n",
    "\n",
    "print(ames_reps)\n",
    "\n",
    "print(sterne_reps)\n",
    "inter_reps = dict()\n",
    "\n",
    "for i in inter:\n",
    "    # Loop through and save any where the number seen in ames and stern differ\n",
    "    if ames_reps[i] != sterne_reps[i]:\n",
    "        inter_reps[i] = (ames_reps[i], sterne_reps[i])\n",
    "\n",
    "df = pd.DataFrame(inter_reps)\n",
    "df = df.transpose()\n",
    "df['Difference'] = df[0] - df[1]     \n",
    "total = df['Difference'].sum()\n",
    "head = ['Tandem Repeat', 'Ames Len', 'Sterne Len', 'Difference']\n",
    "\n",
    "print(tab.tabulate(df, headers=head))\n",
    "print(\"Total (+ means ames is longer, - means Sterne is longer)\", total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
